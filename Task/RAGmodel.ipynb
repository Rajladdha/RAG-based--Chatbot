{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce13108c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import TextLoader, PyPDFLoader, CSVLoader\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3984404e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load documents based on file type\n",
    "def load_documents(file_path):\n",
    "    file_extension = os.path.splitext(file_path)[1].lower()\n",
    "    if file_extension == '.txt':\n",
    "        loader = TextLoader(file_path)\n",
    "    elif file_extension == '.pdf':\n",
    "        loader = PyPDFLoader(file_path)\n",
    "    elif file_extension == '.csv':\n",
    "        loader = CSVLoader(file_path)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported file type: {file_extension}\")\n",
    "    return loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "319f8066",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace 'your_file_path' with the path to your file (PDF, CSV, or TXT)\n",
    "file_path = 'data.pdf'  # Change this to your file path\n",
    "documents = load_documents(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fbf92a00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split into 14 chunks.\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "splits = text_splitter.split_documents(documents)\n",
    "\n",
    "print(f\"Split into {len(splits)} chunks.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc3275df",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "from transformers import pipeline\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "vectorstore = Chroma.from_documents(documents=splits, embedding=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bd542369",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Chapter 5: Optimization Techniques in Deep Learning \\nOptimization is the process of adjusting a model’s parameters to minimize a loss function and \\nachieve optimal performance. This chapter covers essential optimization techniques, their \\nmathematical underpinnings, and practical applications in deep learning. \\n \\n1. Introduction to Optimization \\nOptimization is a core component of deep learning, aiming to find the set of model parameters \\n(weights ) that minimize the loss function . \\n1.1 Role of Optimization in Neural Networks \\n• Adjusts weights and biases to reduce the difference between predicted and actual outputs. \\n• Balances computational efficiency with model convergence. \\n \\n2. Gradient Descent and V ariants \\n2.1 Gradient Descent \\nThe foundational optimization algorithm for training neural networks. \\n• Mathematics: Where: \\no : Learning rate. \\no : Gradient of the loss function with respect to . \\n• Challenges: \\no Slow convergence. \\no Stuck in local minima or saddle points.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query=\"What are challenges in optimization?\"\n",
    "result = vectorstore.similarity_search(query)\n",
    "result[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a868f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using FAISS to check if it is better than Chroma "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7dee9589",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "vectorstore2 = FAISS.from_documents(documents=splits, embedding=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "577f3d30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Chapter 5: Optimization Techniques in Deep Learning \\nOptimization is the process of adjusting a model’s parameters to minimize a loss function and \\nachieve optimal performance. This chapter covers essential optimization techniques, their \\nmathematical underpinnings, and practical applications in deep learning. \\n \\n1. Introduction to Optimization \\nOptimization is a core component of deep learning, aiming to find the set of model parameters \\n(weights ) that minimize the loss function . \\n1.1 Role of Optimization in Neural Networks \\n• Adjusts weights and biases to reduce the difference between predicted and actual outputs. \\n• Balances computational efficiency with model convergence. \\n \\n2. Gradient Descent and V ariants \\n2.1 Gradient Descent \\nThe foundational optimization algorithm for training neural networks. \\n• Mathematics: Where: \\no : Learning rate. \\no : Gradient of the loss function with respect to . \\n• Challenges: \\no Slow convergence. \\no Stuck in local minima or saddle points.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query=\"What are challenges in optimization?\"\n",
    "result = vectorstore2.similarity_search(query)\n",
    "result[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67daa580",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FAISS got samilar result as Chroma so can use either"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef54aa0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "397e07e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from meta_ai_api import MetaAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "06ad84f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize MetaAI\n",
    "ai = MetaAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bc9e32e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_prompt_for_llm(context, question):\n",
    "    prompt = f\"\"\"\n",
    "    Context:\n",
    "    {context}\n",
    "\n",
    "    Question:\n",
    "    {question}\n",
    "\n",
    "    Answer:\n",
    "    \"\"\"\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "203997cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_llm_response(question, vectorstore):\n",
    "    # Retrieve relevant chunks using similarity search\n",
    "    relevant_docs = vectorstore.similarity_search(question, k=3)  # Retrieve top 3 relevant chunks\n",
    "    context = \"\\n\".join([doc.page_content for doc in relevant_docs])\n",
    "    \n",
    "    # Format the prompt\n",
    "    prompt = format_prompt_for_llm(context, question)\n",
    "    \n",
    "    # Get response from MetaAI\n",
    "    response = ai.prompt(message=prompt)\n",
    "    \n",
    "    # Extract the message\n",
    "    message_only = response.get('message', '')\n",
    "    \n",
    "    return message_only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a2759d75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What are challenges in optimization?\n",
      "Response: The challenges in optimization include:\n",
      "Slow convergence: Optimization algorithms may take a long time to converge to the optimal solution.\n",
      "Getting stuck in local minima or saddle points: Optimization algorithms may converge to a local minimum or get stuck in a saddle point, rather than finding the global minimum.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Example usage 1\n",
    "question = \"What are challenges in optimization?\"\n",
    "response = get_llm_response(question, vectorstore)  # Use Chroma vector store\n",
    "print(f\"Question: {question}\")\n",
    "print(f\"Response: {response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c36a35a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What are key features of Scikit-learn?\n",
      "Response: The key features of Scikit-learn include:\n",
      "Easy-to-use API for fast prototyping: Scikit-learn provides a simple and intuitive API for building and testing machine learning models.\n",
      "Preprocessing tools for feature scaling, encoding, and selection: Scikit-learn offers various tools for data preprocessing, including feature scaling, encoding categorical variables, and feature selection.\n",
      "A variety of machine learning algorithms: Scikit-learn supports a wide range of machine learning algorithms, including supervised and unsupervised learning methods.\n",
      "Model evaluation and validation utilities: Scikit-learn provides tools for evaluating and validating machine learning models, including metrics for performance evaluation and methods for hyperparameter tuning.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Example usage 2\n",
    "question = \"What are key features of Scikit-learn?\"\n",
    "response = get_llm_response(question, vectorstore)  # Use Chroma vector store\n",
    "print(f\"Question: {question}\")\n",
    "print(f\"Response: {response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "561ea391",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What are Optimization Techniques in Deep Learning?\n",
      "Response: Optimization techniques in deep learning are methods used to adjust a model's parameters to minimize a loss function and achieve optimal performance. The key optimization techniques include:\n",
      "Gradient Descent (GD): The foundational optimization algorithm for training neural networks.\n",
      "Stochastic Gradient Descent (SGD): Updates parameters using a single data point or mini-batch.\n",
      "Mini-Batch Gradient Descent: Processes small batches of data at a time, balancing computational efficiency and stability.\n",
      "Momentum: Accelerates updates in relevant directions and dampens oscillations.\n",
      "RMSProp: Scales gradients by a moving average of their squared magnitudes.\n",
      "Adam (Adaptive Moment Estimation): Combines the benefits of momentum and RMSProp.\n",
      "These optimization techniques are essential for training deep learning models and achieving optimal performance.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Example usage 3\n",
    "question = \"What are Optimization Techniques in Deep Learning?\"\n",
    "response = get_llm_response(question, vectorstore)  # Use Chroma vector store\n",
    "print(f\"Question: {question}\")\n",
    "print(f\"Response: {response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab902308",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "616982ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
